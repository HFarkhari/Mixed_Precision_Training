{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f678447",
   "metadata": {},
   "source": [
    "# Train LLM with MLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009a2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c668cc-71c0-432d-8c83-f1544072f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler #, autocast\n",
    "from torch import autocast\n",
    "\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a5c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AdamW\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ca5c5e-c3ef-4447-9630-9ae725defbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_funcs import dataset_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cbbdd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=3*8 #24\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3090c6-8c5e-461d-8b49-7639d585c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00439028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = (torch.device('cuda') if torch.cuda.is_available() \n",
    "#           else torch.device('cpu'))\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee233b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model     = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# load locally pretrained\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased_local')\n",
    "# model   = BertForMaskedLM.from_pretrained('bert-base-uncased_local')\n",
    "\n",
    "#load init model (Not trained)\n",
    "model     = BertForMaskedLM.from_pretrained('bert-base-init_local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24b357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mlm_text.text', 'r') as fp:\n",
    "    text = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddff00fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From my grandfather Verus I learned good morals and the government of my temper.',\n",
       " 'From the reputation and remembrance of my father, modesty and a manly character.',\n",
       " 'From my mother, piety and beneficence, and abstinence, not only from evil deeds, but even from evil thoughts; and further, simplicity in my way of living, far removed from the habits of the rich.',\n",
       " 'From my great-grandfather, not to have frequented public schools, and to have had good teachers at home, and to know that on such things a man should spend liberally.',\n",
       " \"From my governor, to be neither of the green nor of the blue party at the games in the Circus, nor a partizan either of the Parmularius or the Scutarius at the gladiators' fights; from him too I learned endurance of labour, and to want little, and to work with my own hands, and not to meddle with other people's affairs, and not to be ready to listen to slander.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d309412",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt', max_length=512,\n",
    "                  truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8fa70f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0],\n",
       "        [  101,   102,     0,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e785ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2013,  2026,  5615,  2310,  7946,  1045,  4342,  2204, 25288,\n",
       "         1998,  1996,  2231,  1997,  2026, 12178,  1012,   102,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "433235ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3067f368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7218de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs.input_ids[0]), type(inputs.input_ids), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f86c4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0],\n",
       "        [  101,   102,     0,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 0,  ..., 0, 0, 0]]), 'labels': tensor([[  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,  7887,  3288,  ...,     0,     0,     0],\n",
       "        [  101,   102,     0,  ...,     0,     0,     0]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac950f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "PAD  = 0\n",
    "CLS  = 101\n",
    "SEP  = 102\n",
    "MASK = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "285e47e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([508, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97d141b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([508, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "\n",
    "# select 15%, remove special tokens from mask\n",
    "mask_arr = ((rand < 0.15)*\n",
    "            (inputs.input_ids != CLS)*\n",
    "            (inputs.input_ids != SEP)*\n",
    "            (inputs.input_ids != PAD))\n",
    "\n",
    "mask_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f647321d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f4f3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index position of true values to be masked --> selection\n",
    "selection = []\n",
    "\n",
    "for i in np.arange(mask_arr.shape[0]):\n",
    "    selection.append(torch.flatten(mask_arr[i].nonzero()).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c718b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 8, 9],\n",
       " [9],\n",
       " [2, 3, 8, 9, 19, 23, 26, 33, 34, 38, 39, 40, 45],\n",
       " [3, 19, 36],\n",
       " [16, 21, 22, 29, 36, 37, 44, 52, 53, 56, 68, 87]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b742249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace mask token with selection \n",
    "for i in np.arange(mask_arr.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73b91563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2013,  2026,  ...,     0,     0,     0],\n",
       "        [  101,  2013,  1996,  ...,     0,     0,     0],\n",
       "        [  101,  2013,   103,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2043, 15223,  ...,     0,     0,     0],\n",
       "        [  101,   103,  3288,  ...,     0,     0,     0],\n",
       "        [  101,   102,     0,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbad7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset to pytorch data object\n",
    "dataset = dataset_obj(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "970e33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, # 16\n",
    "                                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccdfb3",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d70c5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a16cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4); # 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80a20de4-2d3e-42b8-a8d4-25d61f26e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler    = GradScaler()\n",
    "clip_grad = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16ad5d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/22 [00:00<?, ?it/s]/workspace/ubuntu-desktop/BERT/MLM_NSP_fp16_fp32/llm_funcs.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|████████████████████████████████████████████████████| 22/22 [00:07<00:00,  3.09it/s, loss=3.27]\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.28it/s, loss=0.782]\n",
      "Epoch 2: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.27it/s, loss=0.726]\n",
      "Epoch 3: 100%|████████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.26it/s, loss=1.14]\n",
      "Epoch 4: 100%|████████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.26it/s, loss=1.07]\n",
      "Epoch 5: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.26it/s, loss=0.963]\n",
      "Epoch 6: 100%|█████████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.25it/s, loss=1.6]\n",
      "Epoch 7: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.25it/s, loss=0.552]\n",
      "Epoch 8: 100%|████████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.21it/s, loss=1.48]\n",
      "Epoch 9: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.22it/s, loss=0.881]\n",
      "Epoch 10: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.25it/s, loss=1.75]\n",
      "Epoch 11: 100%|████████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.25it/s, loss=1.3]\n",
      "Epoch 12: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.21it/s, loss=1.34]\n",
      "Epoch 13: 100%|██████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.27it/s, loss=0.822]\n",
      "Epoch 14: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.18it/s, loss=1.05]\n",
      "Epoch 15: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.25it/s, loss=1.25]\n",
      "Epoch 16: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.28it/s, loss=1.13]\n",
      "Epoch 17: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.28it/s, loss=1.28]\n",
      "Epoch 18: 100%|███████████████████████████████████████████████████| 22/22 [00:06<00:00,  3.19it/s, loss=1.17]\n",
      "Epoch 19: 100%|███████████████████████████████████████████████████| 22/22 [00:07<00:00,  3.14it/s, loss=1.11]\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "model.zero_grad()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in np.arange(epochs):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "   \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Enables autocasting for the forward pass (model + loss)\n",
    "        with autocast(device_type=device, enabled=True, dtype=torch.float16):\n",
    "            outputs = model(input_ids, \n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        \n",
    "        # clip gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd507d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 136.18 sec\n"
     ]
    }
   ],
   "source": [
    "ed = time.time()\n",
    "print(f'time: {np.round((ed-st),2)} sec')\n",
    "# 19.7G GPU, 136.18 sec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
